# 6장. 분산 키-값 저장소 설계 정리


**단일 서버 기반 키-값 저장소만으로는 급격히 늘어나는 데이터와 트래픽을 감당하기 어렵다. 이를 해결하기 위해 여러 서버에 데이터를 분산 저장하는 분산 키-값 저장소가 필요하다. 하지만 분산 환경에서는 언제나 일관성, 가용성, 네트워크 분할 허용성 사이의 균형을 고려해야 하는데, 이를 설명하는 개념이 바로** **CAP 정리다.**

### 1. CAP 정리
![](IMG_0032.jpeg)

* 분산 시스템은 세 가지 속성 중 두 가지만 동시에 만족할 수 있음.
  1. **Consistency (일관성)**: 모든 노드가 같은 데이터를 본다.
  2. **Availability (가용성)**: 모든 요청이 항상 응답한다.
  3. **Partition Tolerance (파티션 감내)**: 네트워크가 나뉘어도 시스템은 동작한다.
* 키-값 저장소는 **AP 시스템**으로 설계되는 경우가 많다.
  * 분할 허용성을 포기할 수 없으므로, 가용성을 우선시하고 강한 일관성은 일부 포기.

### 2. 핵심 컴포넌트 및 기술
### 2.1 데이터 파티셔닝 (Partitioning)
* 데이터를 키 기반으로 여러 노드에 분산 저장.
* 보통 **안전해싱(Consistent Hashing)**을 사용
  - 규모 확장 자동화: 시스템 부하에 따라 서버가 자동으로 추가되거나 삭제
  - 다양성: 각 서버의 용량에 맞게 가상노드 수 조정

![](IMG_0030.jpeg)

### 2.2 데이터 다중화 (Replication)
* 높은 가용성과 안정성을 위해 각 키를 **N개의 노드**에 복제
* 링을 시계 방향으로 순회하며 **연속된 N개 노드(선호 목록)** 에 사본 저장
* 이를 통해 장애가 나도 데이터 유실 없이 서비스 유지 가능.
![](IMG_0033.jpeg)

⠀
### 2.3 일관성 (Consistency)
- **정족수 파라미터**
  * **N**: 복제본 수, **W**: 쓰기 성공에 필요한 응답 수, **R**: 읽기 성공에 필요한 응답 수
* **W↑/R↑ → 일관성↑ 지연↑ 가용성↓**,
* **W↓/R↓ → 가용성↑ 지연↓ 일관성↓**.
* 일관성모델
  * **강한 일관성**: 읽기 시 최신값 보장(정족수/설정에 따라 달성)
  * **약한 일관성**: 최신값이 아닐 수 있음
  * **최종 일관성**: 시간이 지나면 모든 사본이 수렴(고가용 분산 시스템에서 일반적)

### 2.4 일관성 불일치 해소 - 벡터시계
- 분산 키-값 저장소에서는 하나의 데이터가 여러 노드에 복제되어 저장된다.문제는 **동시에 서로 다른 노드에서 동일한 데이터를 수정할 때** 발생한다. 이 경우 어떤 값이 최신인지 판단하기 어려운데, 이를 해결하기 위한 도구가 **벡터 시계(Vector Clock)**이다.

- 백터시계는
  - 노드 ID, 카운터) 쌍의 집합으로 표현된다.
  * 노드가 데이터를 수정할 때마다 자신에게 해당하는 카운터를 1 증가시킨다.
  * 읽기 시에는 여러 벡터 시계를 비교하여 데이터의 **선후 관계** 또는 **충돌 여부**를 판별한다.
  
- 동작 방식은
  1. **포함 관계 (선후 관계 있음)**
     * 예:
       * 노드 A: {A:1}
       * 노드 B: {A:1, B:1}
     * {A:1} 값은 {A:1, B:1} 값에 포함되므로, {A:1}은 구버전, {A:1, B:1}이 최신 버전이다.
     * 이 경우 충돌이라 보지않고 최신버전을 반환해주면된다
  2. **비포함 관계 (충돌)**
     * 예:
       * 노드 A: {A:2, B:1}
       * 노드 B: {A:1, B:2}
     * 서로 포함되지 않음 → 동시에 수정된 값이므로 충돌 발생.
     * 이 경우 Dynamo는 두 값을 모두 클라이언트(애플리케이션)에 반환한다.
     
- 애플리케이션 병합 로직
  * Dynamo는 충돌을 서버에서 임의로 해결하지 않는다. 클라이언트에게 두 버전을 모두 반환하고
  * 클라이언트 애플리케이션이 **도메인 규칙에 따라 최종 값을 선택**하거나 **병합**해야 한다.
  * 예시:
    * **티켓팅 시스템**: reserved vs available 충돌 → 무조건 reserved를 우선시.
    * **장바구니 시스템**: 두 사용자가 동시에 상품을 담으면 → 최종 장바구니에 두 상품을 합쳐서 병합.
  
### 2.5 장애 처리 (Fault Tolerance)
* **가십 프로토콜(Gossip)**: 노드 상태 주기 교환(장애 감지)
* **Hinted Handoff(임시 위탁 저장)**: 죽은 노드 대신 임시로 기록 → 복구 시 전달
* **Anti-Entropy(Merkle Tree)**: 영역 해시를 비교해 차이만 동기화

### 3. 시스템 아키텍처
![](IMG_0034.jpeg)

- 탈 중앙화 방식
* 클라이언트는 특정 서버를 거치지 않고, 노드에 직접 요청을 보낼 수 있음.
* 모든 노드는 대등한 역할을 수행 (Master가 없음 → Decentralized).
* 구조: 클라이언트 → 코디네이터 노드(요청 받은 노드) → 복제본 노드들.

| **구분** | **Dynamo 스타일 (Decentralized)** | **Master-Slave 스타일 (Centralized)** |
|:-:|:-:|:-:|
| 요청 진입 | 임의의 노드가 코디네이터 | 무조건 마스터 노드 |
| 확장성 | 수평 확장 쉬움 (노드 수 늘리면 됨) | 마스터에 병목 발생 |
| 장애 내성 | 일부 노드 죽어도 나머지로 서비스 가능 | 마스터 죽으면 전체 중단 |
| 일관성 | R, W 값에 따라 조절 (Eventual/Strong) | 기본적으로 강한 일관성 유리 |
| 구현 난이도 | 복잡 (버전 관리, 충돌 해결 필요) | 단순 (권위 노드 1개) |


### 4. 쓰기 경로(Write Path)
1. 클라이언트가 임의 노드에 put 요청 → 그 노드가 **코디네이터**
2. 코디네이터가 일관 해싱으로 **선호 목록 N개**를 찾고 병렬로 쓰기 전파
3. **W개 성공 응답** 수신 시 쓰기 성공 응답 반환
4. 필요 시 **슬로피 쿼럼/힌티드 핸드오프** 적용

### 5. 읽기 경로(Read Path) 
1. 클라이언트가 임의 노드에 get 요청 → 그 노드가 **코디네이터**
2. 코디네이터가 **복제본들**에 병렬 조회, **R개 응답**을 수집
3. 벡터 시계/정책으로 최신값 결정(충돌시 siblings 반환)
4. **Read Repair**로 뒤처진 복제본을 최신화

⠀


